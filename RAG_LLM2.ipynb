{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN7DQh108ugcM5TqlEHtBex"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fa764fb622664381955386d27d7fb0e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_14d2a0b74dfa405186a5c8462b568f42","IPY_MODEL_f1f6d81345224b2c901770c937092919","IPY_MODEL_0abfc6005ada456291e60abbd208ba26"],"layout":"IPY_MODEL_c43a8fdde4be418cb93ec977d43307e0"}},"14d2a0b74dfa405186a5c8462b568f42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f9a0d1632a749b9be6ae203e4fb4c7e","placeholder":"​","style":"IPY_MODEL_856fbdf620064d479c2cebec1869d425","value":"Downloading readme: 100%"}},"f1f6d81345224b2c901770c937092919":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f26c553081c5401fa932b435cf67f692","max":409,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aba25af10c8345d7a0322dd8539c852b","value":409}},"0abfc6005ada456291e60abbd208ba26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b507f05d3c59484b8b7e632c6ed9fc11","placeholder":"​","style":"IPY_MODEL_ac2bd0d6904740fc99764428b3399976","value":" 409/409 [00:00&lt;00:00, 31.2kB/s]"}},"c43a8fdde4be418cb93ec977d43307e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f9a0d1632a749b9be6ae203e4fb4c7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"856fbdf620064d479c2cebec1869d425":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f26c553081c5401fa932b435cf67f692":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aba25af10c8345d7a0322dd8539c852b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b507f05d3c59484b8b7e632c6ed9fc11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac2bd0d6904740fc99764428b3399976":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c1ecf2cc50d4aa1ae283aa6da122588":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7db61d85cf3240f8a2513262e79d2ec8","IPY_MODEL_0b8e3bd7cf82454b83d5a1ea0646e3b4","IPY_MODEL_57244d5d9706434f96178078d2d06f39"],"layout":"IPY_MODEL_f3624a6356c44270abcbf1e764479c91"}},"7db61d85cf3240f8a2513262e79d2ec8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5182ce13685a442499c316f34e1879ae","placeholder":"​","style":"IPY_MODEL_5f8c43ecdf8742119c086b427cf05e25","value":"Downloading data files: 100%"}},"0b8e3bd7cf82454b83d5a1ea0646e3b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9cde58f39054c02bbc5459b3b5b24f0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef2825fbb93d42dd992bb26cd5dc6d20","value":1}},"57244d5d9706434f96178078d2d06f39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26f7be79a6a54a14b0d23a8c9899f157","placeholder":"​","style":"IPY_MODEL_1c64245b4c2840488938ebf7b36e2849","value":" 1/1 [00:00&lt;00:00,  1.64it/s]"}},"f3624a6356c44270abcbf1e764479c91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5182ce13685a442499c316f34e1879ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f8c43ecdf8742119c086b427cf05e25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9cde58f39054c02bbc5459b3b5b24f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef2825fbb93d42dd992bb26cd5dc6d20":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26f7be79a6a54a14b0d23a8c9899f157":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c64245b4c2840488938ebf7b36e2849":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32c427eb1d354db6874ed6e96525128e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2bbec4636ec1443ab723118ecd978c06","IPY_MODEL_37a9889bd111407d8e9af33bdcd3b68c","IPY_MODEL_8d06f23caa62469798e58302f77aae3d"],"layout":"IPY_MODEL_bd60a62a94a64264ab1e3224070d06b7"}},"2bbec4636ec1443ab723118ecd978c06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7ad85bd39314b0a9be92ff77df51e35","placeholder":"​","style":"IPY_MODEL_0e6dcfcfae584b6cbc6b3c4d51bae87e","value":"Downloading data: 100%"}},"37a9889bd111407d8e9af33bdcd3b68c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1acb3af0e1d4aac963cb2a4cbdc290d","max":14417793,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c508f12c17474aee90d8765e778b6f0a","value":14417793}},"8d06f23caa62469798e58302f77aae3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c9a867318a649d6bea506905c398fb6","placeholder":"​","style":"IPY_MODEL_4378fd82ad2548f9a77c62599b3c3436","value":" 14.4M/14.4M [00:00&lt;00:00, 26.4MB/s]"}},"bd60a62a94a64264ab1e3224070d06b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7ad85bd39314b0a9be92ff77df51e35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e6dcfcfae584b6cbc6b3c4d51bae87e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1acb3af0e1d4aac963cb2a4cbdc290d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c508f12c17474aee90d8765e778b6f0a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c9a867318a649d6bea506905c398fb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4378fd82ad2548f9a77c62599b3c3436":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de3d228eb1864b598713ee1ac4b668c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_edaa890e5f5e44de994c4fe57e42d505","IPY_MODEL_dab24cab6daa4039baec16d3d4012b8c","IPY_MODEL_e3085d93e451491f8d44d54cfbfec28d"],"layout":"IPY_MODEL_5a44243059654473ab5c8769947c023a"}},"edaa890e5f5e44de994c4fe57e42d505":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84e399b5b92945adb2d1f43a221d3fa1","placeholder":"​","style":"IPY_MODEL_f31a5e9aab85479ea4563122b1cde532","value":"Extracting data files: 100%"}},"dab24cab6daa4039baec16d3d4012b8c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3356546526e4e7186b9d5fcb2236bd5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a03e304712d4c43a735f0f36f317939","value":1}},"e3085d93e451491f8d44d54cfbfec28d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce6f5b96d057470db9136733745f977b","placeholder":"​","style":"IPY_MODEL_8e1b690d908044d09b800e52e1c7ce79","value":" 1/1 [00:00&lt;00:00, 39.17it/s]"}},"5a44243059654473ab5c8769947c023a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84e399b5b92945adb2d1f43a221d3fa1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f31a5e9aab85479ea4563122b1cde532":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3356546526e4e7186b9d5fcb2236bd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a03e304712d4c43a735f0f36f317939":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ce6f5b96d057470db9136733745f977b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e1b690d908044d09b800e52e1c7ce79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae36bd969ea548958f2b6384f8618150":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c58cba505a547d893f535ebdb009fae","IPY_MODEL_992f06042de44e80aedf484b9b9ad9dd","IPY_MODEL_3ea46754a5224f57a03d4963a1ac4c4d"],"layout":"IPY_MODEL_81e36ec3f405462093c6ae4ee5440b85"}},"0c58cba505a547d893f535ebdb009fae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11dd498a43f64cd1b587ba0494d5f4df","placeholder":"​","style":"IPY_MODEL_0bd0e57bd3df405c9b84c8f55b026be3","value":"Generating train split: "}},"992f06042de44e80aedf484b9b9ad9dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb492afb92804d3e917f9c810bf86c93","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_758983b3e29d4c8489a50b7a4f2cc02a","value":1}},"3ea46754a5224f57a03d4963a1ac4c4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60a1b4a75fed4f3da053fb6aac5d2c48","placeholder":"​","style":"IPY_MODEL_367ee1e622154f6da4e7bcbb0533fcb4","value":" 4838/0 [00:00&lt;00:00, 9431.39 examples/s]"}},"81e36ec3f405462093c6ae4ee5440b85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11dd498a43f64cd1b587ba0494d5f4df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bd0e57bd3df405c9b84c8f55b026be3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb492afb92804d3e917f9c810bf86c93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"758983b3e29d4c8489a50b7a4f2cc02a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"60a1b4a75fed4f3da053fb6aac5d2c48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"367ee1e622154f6da4e7bcbb0533fcb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# **RAG with LLaMa 13B**"],"metadata":{"id":"zc32xM1t334V"}},{"cell_type":"markdown","source":["In this notebook we'll explore how we can use the open source Llama-13b-chat model in both Hugging Face transformers and LangChain."],"metadata":{"id":"ISBLnuTe3Sn9"}},{"cell_type":"markdown","source":["Installing the required libraries"],"metadata":{"id":"igH3vzgwBqpK"}},{"cell_type":"code","source":["!pip install -qU \\\n","  transformers==4.31.0 \\\n","  sentence-transformers==2.2.2 \\\n","  pinecone-client==2.2.2 \\\n","  datasets==2.14.0 \\\n","  accelerate==0.21.0 \\\n","  einops==0.6.1 \\\n","  langchain==0.0.240 \\\n","  xformers==0.0.20 \\\n","  bitsandbytes==0.41.0"],"metadata":{"id":"nBErRb5c3pKb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" Initializing the embedding pipeline that will handle the transformation of our docs into vector embeddings.\n"," Using the sentence-transformers/all-MiniLM-L6-v2 model for embedding."],"metadata":{"id":"pueCAqT3Cbzi"}},{"cell_type":"code","source":["from torch import cuda\n","from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n","\n","embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n","\n","device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n","\n","embed_model = HuggingFaceEmbeddings(\n","    model_name=embed_model_id,\n","    model_kwargs={'device': device},\n","    encode_kwargs={'device': device, 'batch_size': 32}\n",")"],"metadata":{"id":"13aS2pwRCAxz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Using our embedding model to create document embedding"],"metadata":{"id":"EXFAum5JDs9h"}},{"cell_type":"code","source":["docs = [\n","    \"this is one document\",\n","    \"and another document\"\n","]\n","\n","embeddings = embed_model.embed_documents(docs)\n","\n","print(f\"We have {len(embeddings)} doc embeddings, each with \"\n","      f\"a dimensionality of {len(embeddings[0])}.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tTYKyjjCBR6","executionInfo":{"status":"ok","timestamp":1699115806674,"user_tz":420,"elapsed":6358,"user":{"displayName":"Mahalakshmi Jayapal","userId":"17489734921975674885"}},"outputId":"4041ae5e-0da8-41ee-df7b-e7fe5bf71856"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We have 2 doc embeddings, each with a dimensionality of 384.\n"]}]},{"cell_type":"markdown","source":["Building the Vector Database:\n","We will be using the pinecone vector index for our RAG pipeline.\n","Using the embedding pipeline to build our embeddings and store them in a Pinecone vector index. Using my Pinecone API key to initialize the index."],"metadata":{"id":"lBXm9XDKEX0L"}},{"cell_type":"code","source":["import os\n","import pinecone\n","\n","# API key from app.pinecone.io and environment from console\n","PINECONE_API_KEY = 'PINECONE_API_KEY '\n","PINECONE_ENVIRONMENT = 'PINECONE_ENVIRONMENT'\n","\n","pinecone.init(\n","    api_key=os.environ.get(PINECONE_API_KEY) or PINECONE_API_KEY,\n","    environment=os.environ.get(PINECONE_ENVIRONMENT) or PINECONE_ENVIRONMENT\n",")"],"metadata":{"id":"Q571xCe3CBXU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initializing the database"],"metadata":{"id":"kMw364uTF3S3"}},{"cell_type":"code","source":["import time\n","\n","index_name = 'llama-2-rag'\n","\n","if index_name not in pinecone.list_indexes():\n","    pinecone.create_index(\n","        index_name,\n","        dimension=len(embeddings[0]),\n","        metric='cosine'\n","    )\n","    # wait for index to finish initialization\n","    while not pinecone.describe_index(index_name).status['ready']:\n","        time.sleep(1)"],"metadata":{"id":"CuplttEDCBbk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creating the vector database"],"metadata":{"id":"yLKW9bA7F9vN"}},{"cell_type":"code","source":["index = pinecone.Index(index_name)\n","index.describe_index_stats()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZN7XFi3CBiD","executionInfo":{"status":"ok","timestamp":1699115864523,"user_tz":420,"elapsed":533,"user":{"displayName":"Mahalakshmi Jayapal","userId":"17489734921975674885"}},"outputId":"f7b93c9f-3f23-48b6-f055-c65fc7626194"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'dimension': 384,\n"," 'index_fullness': 0.04838,\n"," 'namespaces': {'': {'vector_count': 4838}},\n"," 'total_vector_count': 4838}"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["We will use a set of Arxiv papers related to (and including) the Llama 2 research paper as our dataset."],"metadata":{"id":"FWXwL2vRGURv"}},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","data = load_dataset(\n","    'jamescalam/llama-2-arxiv-papers-chunked',\n","    split='train'\n",")\n","data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264,"referenced_widgets":["fa764fb622664381955386d27d7fb0e7","14d2a0b74dfa405186a5c8462b568f42","f1f6d81345224b2c901770c937092919","0abfc6005ada456291e60abbd208ba26","c43a8fdde4be418cb93ec977d43307e0","3f9a0d1632a749b9be6ae203e4fb4c7e","856fbdf620064d479c2cebec1869d425","f26c553081c5401fa932b435cf67f692","aba25af10c8345d7a0322dd8539c852b","b507f05d3c59484b8b7e632c6ed9fc11","ac2bd0d6904740fc99764428b3399976","5c1ecf2cc50d4aa1ae283aa6da122588","7db61d85cf3240f8a2513262e79d2ec8","0b8e3bd7cf82454b83d5a1ea0646e3b4","57244d5d9706434f96178078d2d06f39","f3624a6356c44270abcbf1e764479c91","5182ce13685a442499c316f34e1879ae","5f8c43ecdf8742119c086b427cf05e25","b9cde58f39054c02bbc5459b3b5b24f0","ef2825fbb93d42dd992bb26cd5dc6d20","26f7be79a6a54a14b0d23a8c9899f157","1c64245b4c2840488938ebf7b36e2849","32c427eb1d354db6874ed6e96525128e","2bbec4636ec1443ab723118ecd978c06","37a9889bd111407d8e9af33bdcd3b68c","8d06f23caa62469798e58302f77aae3d","bd60a62a94a64264ab1e3224070d06b7","e7ad85bd39314b0a9be92ff77df51e35","0e6dcfcfae584b6cbc6b3c4d51bae87e","b1acb3af0e1d4aac963cb2a4cbdc290d","c508f12c17474aee90d8765e778b6f0a","3c9a867318a649d6bea506905c398fb6","4378fd82ad2548f9a77c62599b3c3436","de3d228eb1864b598713ee1ac4b668c0","edaa890e5f5e44de994c4fe57e42d505","dab24cab6daa4039baec16d3d4012b8c","e3085d93e451491f8d44d54cfbfec28d","5a44243059654473ab5c8769947c023a","84e399b5b92945adb2d1f43a221d3fa1","f31a5e9aab85479ea4563122b1cde532","a3356546526e4e7186b9d5fcb2236bd5","8a03e304712d4c43a735f0f36f317939","ce6f5b96d057470db9136733745f977b","8e1b690d908044d09b800e52e1c7ce79","ae36bd969ea548958f2b6384f8618150","0c58cba505a547d893f535ebdb009fae","992f06042de44e80aedf484b9b9ad9dd","3ea46754a5224f57a03d4963a1ac4c4d","81e36ec3f405462093c6ae4ee5440b85","11dd498a43f64cd1b587ba0494d5f4df","0bd0e57bd3df405c9b84c8f55b026be3","cb492afb92804d3e917f9c810bf86c93","758983b3e29d4c8489a50b7a4f2cc02a","60a1b4a75fed4f3da053fb6aac5d2c48","367ee1e622154f6da4e7bcbb0533fcb4"]},"id":"YqjAtgapGQSS","executionInfo":{"status":"ok","timestamp":1699115873010,"user_tz":420,"elapsed":4180,"user":{"displayName":"Mahalakshmi Jayapal","userId":"17489734921975674885"}},"outputId":"a2f66725-8e3f-451c-f655-a05603e8000e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/409 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa764fb622664381955386d27d7fb0e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c1ecf2cc50d4aa1ae283aa6da122588"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/14.4M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32c427eb1d354db6874ed6e96525128e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de3d228eb1864b598713ee1ac4b668c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae36bd969ea548958f2b6384f8618150"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['doi', 'chunk-id', 'chunk', 'id', 'title', 'summary', 'source', 'authors', 'categories', 'comment', 'journal_ref', 'primary_category', 'published', 'updated', 'references'],\n","    num_rows: 4838\n","})"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["Loading the dataset to the vector database."],"metadata":{"id":"PZH9SXCDG9LB"}},{"cell_type":"code","source":["data = data.to_pandas()\n","\n","batch_size = 32\n","\n","for i in range(0, len(data), batch_size):\n","    i_end = min(len(data), i+batch_size)\n","    batch = data.iloc[i:i_end]\n","    ids = [f\"{x['doi']}-{x['chunk-id']}\" for i, x in batch.iterrows()]\n","    texts = [x['chunk'] for i, x in batch.iterrows()]\n","    embeds = embed_model.embed_documents(texts)\n","    # get metadata to store in Pinecone\n","    metadata = [\n","        {'text': x['chunk'],\n","         'source': x['source'],\n","         'title': x['title']} for i, x in batch.iterrows()\n","    ]\n","    # add to Pinecone\n","    index.upsert(vectors=zip(ids, embeds, metadata))"],"metadata":{"id":"rXSWtOiRFpw8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Checking the stats of the vector database after adding the dataset"],"metadata":{"id":"QxpQ7YQQHQow"}},{"cell_type":"code","source":["index.describe_index_stats()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qbu1IrrqHLcF","executionInfo":{"status":"ok","timestamp":1699115982599,"user_tz":420,"elapsed":368,"user":{"displayName":"Mahalakshmi Jayapal","userId":"17489734921975674885"}},"outputId":"2ddc2268-70ec-4982-c88f-f0155650732f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'dimension': 384,\n"," 'index_fullness': 0.04838,\n"," 'namespaces': {'': {'vector_count': 4838}},\n"," 'total_vector_count': 4838}"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":[" To initialize a text-generation pipeline with Hugging Face transformers, initializing the model and move it to CUDA-enabled GPU"],"metadata":{"id":"c28YkfQmH333"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ikzdi_uMI7B-"},"outputs":[],"source":["from torch import cuda, bfloat16\n","import transformers\n","\n","model_id = 'meta-llama/Llama-2-13b-chat-hf'\n","\n","device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n","\n","# set quantization configuration to load large model with less GPU memory\n","# this requires the `bitsandbytes` library\n","bnb_config = transformers.BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type='nf4',\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_compute_dtype=bfloat16\n",")\n","\n","# begin initializing HF items, need auth token for these\n","HF_AUTH = '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'\n","model_config = transformers.AutoConfig.from_pretrained(\n","    model_id,\n","    use_auth_token=HF_AUTH\n",")\n","\n","model = transformers.AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    trust_remote_code=True,\n","    config=model_config,\n","    quantization_config=bnb_config,\n","    device_map='auto',\n","    use_auth_token=HF_AUTH\n",")\n","model.eval()\n","print(f\"Model loaded on {device}\")"]},{"cell_type":"markdown","source":["Tokenizing the plain text to LLM readable token IDs."],"metadata":{"id":"uTUDQk1YIhD3"}},{"cell_type":"code","source":["tokenizer = transformers.AutoTokenizer.from_pretrained(\n","    model_id,\n","    use_auth_token=HF_AUTH\n",")"],"metadata":{"id":"mUmqT_9zITme"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initializing the Hugging Face pipeline"],"metadata":{"id":"vAa7bmepIyIa"}},{"cell_type":"code","source":["generate_text = transformers.pipeline(\n","    model=model, tokenizer=tokenizer,\n","    return_full_text=True,  # langchain expects the full text\n","    task='text-generation',\n","    # we pass model parameters here too\n","    temperature=0.0,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n","    max_new_tokens=512,  # max number of tokens to generate in the output\n","    repetition_penalty=1.1  # without this output begins repeating\n",")"],"metadata":{"id":"l7DBAfltIT2l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Checking the text generation"],"metadata":{"id":"Byh_2hoVJHpi"}},{"cell_type":"code","source":["res = generate_text(\"What is Llama 2\")\n","print(res[0][\"generated_text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88otKk4ZJOjM","executionInfo":{"status":"ok","timestamp":1699116500224,"user_tz":420,"elapsed":62261,"user":{"displayName":"Mahalakshmi Jayapal","userId":"17489734921975674885"}},"outputId":"5251270f-17ca-4377-c1ad-69ac80b0c92a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["What is Llama 2.0?\n","\n","Llama 2.0 is a new version of the popular open-source vulnerability scanner and web application security testing tool, OWASP ZAP (Zed Attack Proxy). It was released in December 2019 and includes several new features and improvements over the previous version. Some of the key changes in Llama 2.0 include:\n","\n","1. Improved performance: Llama 2.0 is faster and more efficient than its predecessor, with improved performance and reduced memory usage.\n","2. Enhanced user interface: The new version has a modernized user interface that is easier to use and navigate, with improved layout and design.\n","3. New features: Llama 2.0 includes several new features, such as support for testing WebSocket applications, improved handling of HTTP/2 requests, and better integration with other tools and plugins.\n","4. Better compatibility: Llama 2.0 is compatible with a wider range of operating systems and platforms, including Windows, macOS, and Linux.\n","5. Enhanced reporting: The new version includes improved reporting capabilities, with more detailed and accurate information about vulnerabilities and security issues.\n","6. Support for new protocols: Llama 2.0 supports the latest web application protocols, including HTTP/2 and WebSockets, and can detect vulnerabilities in these protocols.\n","7. Improved plugin architecture: The new version has an improved plugin architecture that makes it easier for developers to create and install custom plugins.\n","8. Better support for mobile applications: Llama 2.0 includes improved support for testing mobile applications, with better handling of mobile-specific protocols and technologies.\n","\n","Overall, Llama 2.0 is a significant improvement over the previous version, with many new features and improvements that make it a powerful tool for web application security testing and vulnerability assessment.\n"]}]},{"cell_type":"code","source":["res = generate_text(\"what is so special about llama 2?\")\n","print(res[0][\"generated_text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UeWW-5mjJvLo","executionInfo":{"status":"ok","timestamp":1699116586814,"user_tz":420,"elapsed":72675,"user":{"displayName":"Mahalakshmi Jayapal","userId":"17489734921975674885"}},"outputId":"283c5409-c922-48bd-fecf-cc81a5242bc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["what is so special about llama 2?\n","\n","Answer: Llama 2 is a unique and special animal for several reasons. Here are some of the most notable features that make it stand out:\n","\n","1. Size: Llamas are known for their size, and Llama 2 is no exception. It is one of the largest llamas in existence, with some individuals reaching heights of over 6 feet (1.8 meters) at the shoulder and weighing up to 400 pounds (180 kilograms).\n","2. Coat: Llama 2 has a distinctive coat that is soft, fine, and silky to the touch. The coat can be a variety of colors, including white, cream, beige, and brown.\n","3. Temperament: Llama 2 is known for its friendly and docile nature. They are social animals that thrive on human interaction and are often used as therapy animals due to their calm demeanor.\n","4. Intelligence: Llama 2 is highly intelligent and can learn a wide range of tasks, from simple commands like \"sit\" and \"stay\" to more complex tasks like pulling carts or carrying packs.\n","5. Adaptability: Llama 2 is highly adaptable and can survive in a variety of environments, from high-altitude mountains to hot deserts. They are also able to digest a wide range of plants, making them a versatile and valuable animal in many different ecosystems.\n","6. Long lifespan: Llama 2 can live for up to 20 years in captivity, which is longer than many other domesticated animals. This makes them a long-term investment for farmers and breeders.\n","7. Low maintenance: Llama 2 is relatively low maintenance compared to other livestock. They require minimal equipment and infrastructure, and they are easy to handle and care for.\n","8. Dual purpose: Llama 2 is a dual-purpose animal, meaning they can be raised for both their meat and their wool. Their meat is lean and nutritious, while their wool is soft and warm.\n","9. Resistance to disease: Llama 2 is resistant to many diseases that affect other livestock, such as brucellosis and tuberculosis. This makes them a reliable and hard\n"]}]},{"cell_type":"markdown","source":["Integrating with langchain to connect the vector database"],"metadata":{"id":"sHTJkEW-J7Px"}},{"cell_type":"code","source":["from langchain.llms import HuggingFacePipeline\n","\n","llm = HuggingFacePipeline(pipeline=generate_text)"],"metadata":{"id":"hJgP70ZpJ79t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm(prompt=\"What is Llama 2\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"CztdVD7TKdlZ","executionInfo":{"status":"ok","timestamp":1699116739958,"user_tz":420,"elapsed":60015,"user":{"displayName":"Mahalakshmi Jayapal","userId":"17489734921975674885"}},"outputId":"205ff043-92d0-4c6d-b7ed-36d5270f7d3b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'.0?\\n\\nLlama 2.0 is a new version of the popular open-source vulnerability scanner and web application security testing tool, OWASP ZAP (Zed Attack Proxy). It was released in December 2019 and includes several new features and improvements over the previous version. Some of the key changes in Llama 2.0 include:\\n\\n1. Improved performance: Llama 2.0 is faster and more efficient than its predecessor, with improved performance and reduced memory usage.\\n2. Enhanced user interface: The new version has a modernized user interface that is easier to use and navigate, with improved layout and design.\\n3. New features: Llama 2.0 includes several new features, such as support for testing WebSocket applications, improved handling of HTTP/2 requests, and better integration with other tools and plugins.\\n4. Better compatibility: Llama 2.0 is compatible with a wider range of operating systems and platforms, including Windows, macOS, and Linux.\\n5. Enhanced reporting: The new version includes improved reporting capabilities, with more detailed and accurate information about vulnerabilities and security issues.\\n6. Support for new protocols: Llama 2.0 supports the latest web application protocols, including HTTP/2 and WebSockets, and can detect vulnerabilities in these protocols.\\n7. Improved plugin architecture: The new version has an improved plugin architecture that makes it easier for developers to create and install custom plugins.\\n8. Better support for mobile applications: Llama 2.0 includes improved support for testing mobile applications, with better handling of mobile-specific protocols and technologies.\\n\\nOverall, Llama 2.0 is a significant improvement over the previous version, with many new features and improvements that make it a powerful tool for web application security testing and vulnerability assessment.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["llm(prompt=\"what is so special about llama 2?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"mLjH9_9sKhTX","executionInfo":{"status":"ok","timestamp":1699116817687,"user_tz":420,"elapsed":72710,"user":{"displayName":"Mahalakshmi Jayapal","userId":"17489734921975674885"}},"outputId":"988b8227-6098-4c6d-a477-981bdb33ea5d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\nAnswer: Llama 2 is a unique and special animal for several reasons. Here are some of the most notable features that make it stand out:\\n\\n1. Size: Llamas are known for their size, and Llama 2 is no exception. It is one of the largest llamas in existence, with some individuals reaching heights of over 6 feet (1.8 meters) at the shoulder and weighing up to 400 pounds (180 kilograms).\\n2. Coat: Llama 2 has a distinctive coat that is soft, fine, and silky to the touch. The coat can be a variety of colors, including white, cream, beige, and brown.\\n3. Temperament: Llama 2 is known for its friendly and docile nature. They are social animals that thrive on human interaction and are often used as therapy animals due to their calm demeanor.\\n4. Intelligence: Llama 2 is highly intelligent and can learn a wide range of tasks, from simple commands like \"sit\" and \"stay\" to more complex tasks like pulling carts or carrying packs.\\n5. Adaptability: Llama 2 is highly adaptable and can survive in a variety of environments, from high-altitude mountains to hot deserts. They are also able to digest a wide range of plants, making them a versatile and valuable animal in many different ecosystems.\\n6. Long lifespan: Llama 2 can live for up to 20 years in captivity, which is longer than many other domesticated animals. This makes them a long-term investment for farmers and breeders.\\n7. Low maintenance: Llama 2 is relatively low maintenance compared to other livestock. They require minimal equipment and infrastructure, and they are easy to handle and care for.\\n8. Dual purpose: Llama 2 is a dual-purpose animal, meaning they can be raised for both their meat and their wool. Their meat is lean and nutritious, while their wool is soft and warm.\\n9. Resistance to disease: Llama 2 is resistant to many diseases that affect other livestock, such as brucellosis and tuberculosis. This makes them a reliable and hard'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["Initializing the retrieval QA chain for the RAG pipeline"],"metadata":{"id":"GQbWJ-vOK5QZ"}},{"cell_type":"code","source":["from langchain.vectorstores import Pinecone\n","\n","text_field = 'text'  # field in metadata that contains text content\n","\n","vectorstore = Pinecone(\n","    index, embed_model.embed_query, text_field\n",")"],"metadata":{"id":"K99_F7ZnKiKz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Checking the similarity search with the results of the top 3 searches"],"metadata":{"id":"4dwJnbk0LM-1"}},{"cell_type":"code","source":["query = 'what makes llama 2 special?'\n","\n","vectorstore.similarity_search(\n","    query,  # the search query\n","    k=3  # returns top 3 most relevant chunks of text\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G2DLn1pxLHuX","executionInfo":{"status":"ok","timestamp":1699116883029,"user_tz":420,"elapsed":536,"user":{"displayName":"Mahalakshmi Jayapal","userId":"17489734921975674885"}},"outputId":"06b5721d-70b4-4b46-a87c-7715b2472f9e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(page_content='Ricardo Lopez-Barquilla, Marc Shedroﬀ, Kelly Michelena, Allie Feinstein, Amit Sangani, Geeta\\nChauhan,ChesterHu,CharltonGholson,AnjaKomlenovic,EissaJamil,BrandonSpence,Azadeh\\nYazdan, Elisa Garcia Anzano, and Natascha Parks.\\n•ChrisMarra,ChayaNayak,JacquelinePan,GeorgeOrlin,EdwardDowling,EstebanArcaute,Philomena Lobo, Eleonora Presani, and Logan Kerr, who provided helpful product and technical organization support.\\n46\\n•Armand Joulin, Edouard Grave, Guillaume Lample, and Timothee Lacroix, members of the original\\nLlama team who helped get this work started.\\n•Drew Hamlin, Chantal Mora, and Aran Mun, who gave us some design input on the ﬁgures in the\\npaper.\\n•Vijai Mohan for the discussions about RLHF that inspired our Figure 20, and his contribution to the\\ninternal demo.\\n•Earlyreviewersofthispaper,whohelpedusimproveitsquality,includingMikeLewis,JoellePineau,\\nLaurens van der Maaten, Jason Weston, and Omer Levy.', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'}),\n"," Document(page_content='our responsible release strategy can be found in Section 5.3.\\nTheremainderofthispaperdescribesourpretrainingmethodology(Section2),ﬁne-tuningmethodology\\n(Section 3), approach to model safety (Section 4), key observations and insights (Section 5), relevant related\\nwork (Section 6), and conclusions (Section 7).\\n‡https://ai.meta.com/resources/models-and-libraries/llama/\\n§We are delaying the release of the 34B model due to a lack of time to suﬃciently red team.\\n¶https://ai.meta.com/llama\\n‖https://github.com/facebookresearch/llama\\n4\\nFigure 4: Training of L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc : This process begins with the pretraining ofL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle using publicly\\navailableonlinesources. Followingthis,wecreateaninitialversionof L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc throughtheapplication', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'}),\n"," Document(page_content='asChatGPT,BARD,andClaude. TheseclosedproductLLMsareheavilyﬁne-tunedtoalignwithhuman\\npreferences, which greatly enhances their usability and safety. This step can require signiﬁcant costs in\\ncomputeandhumanannotation,andisoftennottransparentoreasilyreproducible,limitingprogresswithin\\nthe community to advance AI alignment research.\\nIn this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, L/l.sc/a.sc/m.sc/a.sc /two.taboldstyle and\\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc , at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested,\\nL/l.sc/a.sc/m.sc/a.sc /two.taboldstyle-C/h.sc/a.sc/t.sc models generally perform better than existing open-source models. They also appear to\\nbe on par with some of the closed-source models, at least on the human evaluations we performed (see', metadata={'source': 'http://arxiv.org/pdf/2307.09288', 'title': 'Llama 2: Open Foundation and Fine-Tuned Chat Models'})]"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["Adding the vector database to the LLM for the RAG pipeline"],"metadata":{"id":"pgwNUeCuLg09"}},{"cell_type":"code","source":["from langchain.chains import RetrievalQA\n","\n","rag_pipeline = RetrievalQA.from_chain_type(\n","    llm=llm, chain_type='stuff',\n","    retriever=vectorstore.as_retriever()\n",")"],"metadata":{"id":"ED8DIqTCLVin"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["LLM without RAG"],"metadata":{"id":"VWjJ96I1L2Kj"}},{"cell_type":"code","source":["llm('what is so special about llama 2?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"vzEvgN2HL0xQ","executionInfo":{"status":"ok","timestamp":1699116970563,"user_tz":420,"elapsed":72761,"user":{"displayName":"Mahalakshmi Jayapal","userId":"17489734921975674885"}},"outputId":"b9350bda-18a8-400d-c138-50d8aef4675a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\nAnswer: Llama 2 is a unique and special animal for several reasons. Here are some of the most notable features that make it stand out:\\n\\n1. Size: Llamas are known for their size, and Llama 2 is no exception. It is one of the largest llamas in existence, with some individuals reaching heights of over 6 feet (1.8 meters) at the shoulder and weighing up to 400 pounds (180 kilograms).\\n2. Coat: Llama 2 has a distinctive coat that is soft, fine, and silky to the touch. The coat can be a variety of colors, including white, cream, beige, and brown.\\n3. Temperament: Llama 2 is known for its friendly and docile nature. They are social animals that thrive on human interaction and are often used as therapy animals due to their calm demeanor.\\n4. Intelligence: Llama 2 is highly intelligent and can learn a wide range of tasks, from simple commands like \"sit\" and \"stay\" to more complex tasks like pulling carts or carrying packs.\\n5. Adaptability: Llama 2 is highly adaptable and can survive in a variety of environments, from high-altitude mountains to hot deserts. They are also able to digest a wide range of plants, making them a versatile and valuable animal in many different ecosystems.\\n6. Long lifespan: Llama 2 can live for up to 20 years in captivity, which is longer than many other domesticated animals. This makes them a long-term investment for farmers and breeders.\\n7. Low maintenance: Llama 2 is relatively low maintenance compared to other livestock. They require minimal equipment and infrastructure, and they are easy to handle and care for.\\n8. Dual purpose: Llama 2 is a dual-purpose animal, meaning they can be raised for both their meat and their wool. Their meat is lean and nutritious, while their wool is soft and warm.\\n9. Resistance to disease: Llama 2 is resistant to many diseases that affect other livestock, such as brucellosis and tuberculosis. This makes them a reliable and hard'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["LLM With RAG"],"metadata":{"id":"oT0e_AGhMCKX"}},{"cell_type":"code","source":["rag_pipeline('what is so special about llama 2?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBH5zbnAMA5y","executionInfo":{"status":"ok","timestamp":1699117033946,"user_tz":420,"elapsed":32622,"user":{"displayName":"Mahalakshmi Jayapal","userId":"17489734921975674885"}},"outputId":"c87d4717-9f7c-4243-b83b-88e5339e1130"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'query': 'what is so special about llama 2?',\n"," 'result': ' Llama 2 is a collection of pretrained and fine-tuned large language models (LLMs) developed and released by GenAI, Meta. The models are optimized for dialogue use cases and outperform open-source chat models on most benchmarks tested. Additionally, they are considered a suitable substitute for closed-source models like ChatGPT, BARD, and Claude.\\n\\nPlease let me know if you need any further information or clarification.'}"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["Without RAG the LLM talks about the animal Llama, with RAG the LLM explains about the pretrained and fine tuned LLMs"],"metadata":{"id":"KhHJD_HJ-XAz"}}]}